{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1009firsthalf_averaged.json\n",
      "-> reading:  1009firsthalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1009secondhalf_averaged.json\n",
      "-> reading:  1009secondhalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1011firsthalf_averaged.json\n",
      "-> reading:  1011firsthalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1011secondhalf_averaged.json\n",
      "-> reading:  1011secondhalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1013firsthalf_averaged.json\n",
      "-> reading:  1013firsthalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1013secondhalf_averaged.json\n",
      "-> reading:  1013secondhalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1016firsthalf_averaged.json\n",
      "-> reading:  1016firsthalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1016secondhalf_averaged.json\n",
      "-> reading:  1016secondhalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1017firsthalf_averaged.json\n",
      "-> reading:  1017firsthalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1017secondhalf_averaged.json\n",
      "-> reading:  1017secondhalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1019firsthalf_averaged.json\n",
      "-> reading:  1019firsthalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1019secondhalf_averaged.json\n",
      "-> reading:  1019secondhalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1021firsthalf_averaged.json\n",
      "-> reading:  1021firsthalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1021secondhalf_averaged.json\n",
      "-> reading:  1021secondhalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1085firsthalf_averaged.json\n",
      "-> reading:  1085firsthalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1085secondhalf_averaged.json\n",
      "-> reading:  1085secondhalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1086firsthalf_averaged.json\n",
      "-> reading:  1086firsthalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1086secondhalf_averaged.json\n",
      "-> reading:  1086secondhalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1089firsthalf_averaged.json\n",
      "-> reading:  1089firsthalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1089secondhalf_averaged.json\n",
      "-> reading:  1089secondhalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1094firsthalf_averaged.json\n",
      "-> reading:  1094firsthalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1094secondhalf_averaged.json\n",
      "-> reading:  1094secondhalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1096firsthalf_averaged.json\n",
      "-> reading:  1096firsthalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1096secondhalf_averaged.json\n",
      "-> reading:  1096secondhalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1100firsthalf_averaged.json\n",
      "-> reading:  1100firsthalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1100secondhalf_averaged.json\n",
      "-> reading:  1100secondhalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1102firsthalf_averaged.json\n",
      "-> reading:  1102firsthalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1102secondhalf_averaged.json\n",
      "-> reading:  1102secondhalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1103firsthalf_averaged.json\n",
      "-> reading:  1103firsthalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1103secondhalf_averaged.json\n",
      "-> reading:  1103secondhalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1104firsthalf_averaged.json\n",
      "-> reading:  1104firsthalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1104secondhalf_averaged.json\n",
      "-> reading:  1104secondhalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1111firsthalf_averaged.json\n",
      "-> reading:  1111firsthalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1111secondhalf_averaged.json\n",
      "-> reading:  1111secondhalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1115firsthalf_averaged.json\n",
      "-> reading:  1115firsthalf_averaged.json\n",
      "(1, 0, 0)\n",
      "1115secondhalf_averaged.json\n",
      "-> reading:  1115secondhalf_averaged.json\n",
      "(1, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "# __author__ = 'Adam Li'\n",
    "import pymongo\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#directory Path to find all the log files/data from a game session ***Probably will be changed***\n",
    "dataDirPath = \"/Users/adam2392/Desktop/Microsoft-Rugby-Machine-Learning/preprocessed_averaged/\"\n",
    "\n",
    "# dump lines into specified database\n",
    "def dumpLinesIntoDatabase(lines):\n",
    "    \n",
    "    # statistics on performance\n",
    "    countOK = 0\n",
    "    countDUP = 0\n",
    "    countFAIL = 0\n",
    "    total = 0\n",
    "    \n",
    "#     _id = db.hackprinceton.insert_many(lines)\n",
    "    # loop through lines\n",
    "    for line in lines:\n",
    "        try:\n",
    "            jsonObj = json.loads(line)\n",
    "        except ValueError:\n",
    "            jsonObj = json.loads(json.dumps(line))\n",
    "        \n",
    "        total += 1\n",
    "\n",
    "        try:\n",
    "            _id = db.hackprinceton.insert_one(jsonObj)\n",
    "            countOK += 1\n",
    "        except pymongo.errors.DuplicateKeyError:\n",
    "            countDUP += 1\n",
    "        except:\n",
    "            countFAIL += 1\n",
    "            traceback.print_exc()\n",
    "            break\n",
    "            \n",
    "    # returns\n",
    "    return (countOK, countDUP, countFAIL)\n",
    "\n",
    "# try to connect w/ mongodb server\n",
    "isConnected = False\n",
    "\n",
    "try:\n",
    "    conn = pymongo.MongoClient()\n",
    "    db = conn.hackprinceton  # connect to the 'hackprinceton' db\n",
    "    isConnected = True\n",
    "except:\n",
    "    print \"Connection Failed\"\n",
    "    \n",
    "lsDir = os.listdir(dataDirPath)\n",
    "for eachFile in lsDir:\n",
    "    \n",
    "    # if it is our json file\n",
    "    if \".json\" in eachFile:\n",
    "        print eachFile\n",
    "        print '->', 'reading: ', eachFile\n",
    "        \n",
    "        firstorsecond = \n",
    "        \n",
    "        # dump data into database\n",
    "        pathFile = dataDirPath + eachFile\n",
    "        linesInFile = open(pathFile).readlines()\n",
    "#         for line in linesInFile:\n",
    "#             print line\n",
    "#             line = line[line.find(\"{\") : ]\n",
    "#             print line\n",
    "#             jsonObj = json.loads(line)\n",
    "#             print jsonObj\n",
    "        print dumpLinesIntoDatabase(linesInFile)\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
